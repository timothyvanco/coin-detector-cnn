{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from code import ImageToArrayPreprocessor\n",
    "from code import SimplePreprocessor\n",
    "from code import SimpleDatasetLoader\n",
    "from code import ShallowNet\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--dataset\", required=True, help=\"path to input dataset\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# grab the list of images that we'll be describing\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
    "\n",
    "# initialize the image preprocessors\n",
    "sp = SimplePreprocessor(200, 200)\n",
    "iap = ImageToArrayPreprocessor()\n",
    "\n",
    "# load the dataset from disk then scale the raw pixel intensities\n",
    "# to the range [0, 1]\n",
    "sdl = SimpleDatasetLoader(preprocessors=[sp, iap])\n",
    "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
    "data = data.astype(\"float\") / 255.0\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "trainY = LabelBinarizer().fit_transform(trainY)\n",
    "testY = LabelBinarizer().fit_transform(testY)\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=0.005)\n",
    "model = ShallowNet.build(width=200, height=200, depth=3, classes=4)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=32, epochs=50, verbose=1)\n",
    "\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1),\n",
    "\ttarget_names=[\"brass\", \"copper\", \"czech50\", \"silver\"]))\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 50), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 50), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, 50), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, 50), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
